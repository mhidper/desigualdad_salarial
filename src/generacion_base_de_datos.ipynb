{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f9feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EES10_14_18.ipynb\n",
    "# Project: OBSERVATORIO LA CAIXA\n",
    "# Converted from Stata to Python\n",
    "# 17/02/2021, version 1\n",
    "# Manuel Alejandro Hidalgo (Universidad Pablo de Olavide)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import patoolib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc10ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\data\\EES10_14_18.zip...\n",
      "Data already extracted in ..\\data\\EES10_14_18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define paths relative to the 'src' directory where the notebook is\n",
    "zip_path = os.path.join('..', 'data', 'EES10_14_18.zip')\n",
    "extract_path = os.path.join('..', 'data')\n",
    "# This will be the base path for the loaded data, assuming the zip extracts a folder with its name\n",
    "data_base_path = os.path.join(extract_path, 'EES10_14_18')\n",
    "\n",
    "# Extract data\n",
    "print(f\"Extracting {zip_path}...\")\n",
    "if not os.path.exists(data_base_path):\n",
    "    patoolib.extract_archive(zip_path, outdir=extract_path)\n",
    "    print(f\"Extraction completed in {extract_path}\")\n",
    "else:\n",
    "    print(f\"Data already extracted in {data_base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f31e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2018 data...\n",
      "2018 data loaded: 216726 observations\n",
      "Starting variable transformations...\n",
      "Basic salary variables created.\n",
      "String to numeric conversions completed.\n",
      "Loading 2022 data...\n",
      "2022 data loaded: 216726 observations\n",
      "Starting variable transformations...\n",
      "Basic salary variables created.\n",
      "String to numeric conversions completed.\n",
      "Loading 2010 data...\n",
      "2010 data loaded: 216769 observations\n",
      "Combined dataset after 2010: 673985 observations\n",
      "Creating salary and time variables...\n",
      "Salary and hours calculations completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Usuario\\anaconda3\\envs\\tftimeseriesII\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables...\n",
      "Age and sector dummies created.\n",
      "Data processing completed successfully!\n",
      "Final dataset shape: (883421, 123)\n",
      "Years in dataset: [2010, 2014, 2018, 2022]\n",
      "Cleaning up extracted folder: ..\\data\\EES10_14_18\n",
      "Cleanup successful.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load 2018 data\n",
    "print(\"Loading 2018 data...\")\n",
    "df = pd.read_stata(os.path.join(data_base_path, 'datos_salarial18', 'EES18.dta'))\n",
    "print(f\"2018 data loaded: {df.shape[0]} observations\")\n",
    "df['year'] = 2018\n",
    "\n",
    "# Ajuste nombre y variables a modelo 10_14\n",
    "df = df.rename(columns={\n",
    "    'idenccc': 'ordenccc',\n",
    "    'nuts1': 'region',\n",
    "    'cnace': 'secc',\n",
    "    'regulacion': 'convenio',\n",
    "    'cno1': 'cno2',\n",
    "    'estu': 'cestudio',  # similar al de 14\n",
    "    'anos2': 'edad'\n",
    "})\n",
    "\n",
    "print(\"Starting variable transformations...\")\n",
    "\n",
    "# Generate new variables\n",
    "df['salbruto'] = df['retrinoin'] + df['retriin']\n",
    "df['vesp'] = df['vespnoin'] + df['vespin']\n",
    "print(\"Basic salary variables created.\")\n",
    "\n",
    "# Convert string variables to numeric (equivalent to destring)\n",
    "df['sexo'] = pd.to_numeric(df['sexo'], errors='coerce')\n",
    "df['edad'] = pd.to_numeric(df['edad'], errors='coerce')\n",
    "df['tipojor'] = pd.to_numeric(df['tipojor'], errors='coerce')\n",
    "df['control'] = pd.to_numeric(df['control'], errors='coerce')\n",
    "df['mercado'] = pd.to_numeric(df['mercado'], errors='coerce')\n",
    "df['convenio'] = pd.to_numeric(df['convenio'], errors='coerce')\n",
    "df['tipopais'] = pd.to_numeric(df['tipopais'], errors='coerce')\n",
    "print(\"String to numeric conversions completed.\")\n",
    "\n",
    "# Load 2022 data\n",
    "print(\"Loading 2022 data...\")\n",
    "df_2022 = pd.read_stata(os.path.join(data_base_path, 'datos_salarial22', 'EES_2022.dta'))\n",
    "df_2022.columns = df_2022.columns.str.lower()\n",
    "print(f\"2022 data loaded: {df.shape[0]} observations\")\n",
    "df_2022['year'] = 2022\n",
    "\n",
    "# Ajuste nombre y variables a modelo 10_14\n",
    "df_2022 = df_2022.rename(columns={\n",
    "    'idenccc': 'ordenccc',\n",
    "    'nuts1': 'region',\n",
    "    'cnace': 'secc',\n",
    "    'regulacion': 'convenio',\n",
    "    'cno1': 'cno2',\n",
    "    'estu': 'cestudio',  # similar al de 14\n",
    "    'anos2': 'edad'\n",
    "})\n",
    "\n",
    "print(\"Starting variable transformations...\")\n",
    "\n",
    "# Generate new variables\n",
    "df_2022['salbruto'] = df_2022['retrinoin'] + df_2022['retriin']\n",
    "df_2022['vesp'] = df_2022['vespnoin'] + df_2022['vespin']\n",
    "print(\"Basic salary variables created.\")\n",
    "\n",
    "# Convert string variables to numeric (equivalent to destring)\n",
    "df_2022['sexo'] = pd.to_numeric(df_2022['sexo'], errors='coerce')\n",
    "df_2022['edad'] = pd.to_numeric(df_2022['edad'], errors='coerce')\n",
    "df_2022['tipojor'] = pd.to_numeric(df_2022['tipojor'], errors='coerce')\n",
    "df_2022['control'] = pd.to_numeric(df_2022['control'], errors='coerce')\n",
    "df_2022['mercado'] = pd.to_numeric(df_2022['mercado'], errors='coerce')\n",
    "df_2022['convenio'] = pd.to_numeric(df_2022['convenio'], errors='coerce')\n",
    "df_2022['tipopais'] = pd.to_numeric(df_2022['tipopais'], errors='coerce')\n",
    "print(\"String to numeric conversions completed.\")\n",
    "\n",
    "\n",
    "df = pd.concat([df, df_2022], ignore_index=True, sort=False)\n",
    "\n",
    "# Append 2010 data\n",
    "print(\"Loading 2010 data...\")\n",
    "df_2010 = pd.read_stata(os.path.join(data_base_path, 'datos_salarial10', 'EES10.dta'))\n",
    "print(f\"2010 data loaded: {df_2010.shape[0]} observations\")\n",
    "df = pd.concat([df, df_2010], ignore_index=True, sort=False)\n",
    "print(f\"Combined dataset after 2010: {df.shape[0]} observations\")\n",
    "\n",
    "# Replace cestudio for 2010 data\n",
    "df.loc[(df['cestudio'] == \"6\") & (df['year'] == 2010), 'cestudio'] = \"5\"\n",
    "df.loc[(df['cestudio'] == \"7\") & (df['year'] == 2010), 'cestudio'] = \"6\"\n",
    "df.loc[(df['cestudio'] == \"8\") & (df['year'] == 2010), 'cestudio'] = \"7\"\n",
    "\n",
    "# Append 2014 data\n",
    "df_2014 = pd.read_stata(os.path.join(data_base_path, 'datos_salarial14', 'EES14.dta'))\n",
    "df = pd.concat([df, df_2014], ignore_index=True, sort=False)\n",
    "\n",
    "# Replace cestudio\n",
    "df.loc[df['cestudio'] == \"5\", 'cestudio'] = \"4\"\n",
    "\n",
    "# Generate new variables\n",
    "print(\"Creating salary and time variables...\")\n",
    "df['diasrelaba'] = df['drelabam'] * 30.42 + df['drelabad']\n",
    "df.loc[df['diasrelaba'] > 365, 'diasrelaba'] = 365\n",
    "\n",
    "df['diasano'] = df['diasrelaba'] - df['dsiespa2'] - df['dsiespa4']\n",
    "\n",
    "# Salario anual total\n",
    "df['salbase'] = (365 / df['diasano']) * (df['salbruto'] + df['vesp']) / 12\n",
    "# Salario mensual total\n",
    "df['salmes'] = df['salbase'] + df['comsal'] + df['phextra'] + df['extraorm']\n",
    "# Salario neto\n",
    "df['salneto'] = df['salmes'] - df['cotiza'] - df['irpfmes']\n",
    "\n",
    "df['horas'] = ((df['jsp1'] + (df['jsp2'] / 60)) * 4.35) + df['hextra']\n",
    "df['salhora'] = df['salmes'] / df['horas']\n",
    "# Sin horas extras\n",
    "df['salbasehora'] = df['salbase'] / ((df['jsp1'] + (df['jsp2'] / 60)) * 4.35)\n",
    "df['restosal'] = df['salhora'] - df['salbasehora']\n",
    "\n",
    "# Precios constantes de 2010\n",
    "df.loc[df['year'] == 2014, 'salhora'] = df.loc[df['year'] == 2014, 'salhora'] * 96.903 / 103.732\n",
    "\n",
    "df['lsalhora'] = np.log(df['salhora'])\n",
    "df['lsalbasehora'] = np.log(df['salbasehora'])\n",
    "df['lrestosal'] = np.log(df['restosal'])\n",
    "df['horascontr'] = np.log(df['jsp1'])\n",
    "print(\"Salary and hours calculations completed.\")\n",
    "\n",
    "# Recode variables\n",
    "df.loc[df['sexo'] == 1, 'sexo'] = 0\n",
    "df.loc[df['sexo'] == 6, 'sexo'] = 1\n",
    "\n",
    "df['control'] = df['control'] - 1\n",
    "df['tipopais'] = df['tipopais'] - 1\n",
    "\n",
    "df['tipojor'] = pd.to_numeric(df['tipojor'], errors='coerce')\n",
    "df.loc[df['tipojor'] == 1, 'tipojor'] = 0\n",
    "df.loc[df['tipojor'] == 2, 'tipojor'] = 1\n",
    "df = df.rename(columns={'tipojor': 'parcial'})\n",
    "\n",
    "df['tipoconb'] = pd.to_numeric(df['tipocon'], errors='coerce')\n",
    "df = df.drop(columns=['tipocon'])\n",
    "df = df.rename(columns={'tipoconb': 'tipocon'})\n",
    "df.loc[df['tipocon'] == 2, 'tipocon'] = 0\n",
    "df = df.rename(columns={'tipocon': 'indefin'})\n",
    "\n",
    "# Create age dummy variables\n",
    "print(\"Creating dummy variables...\")\n",
    "edad_dummies = pd.get_dummies(df['edad'], prefix='age')\n",
    "df = pd.concat([df, edad_dummies], axis=1)\n",
    "\n",
    "# Create sector dummy variables\n",
    "sect_dummies = pd.get_dummies(df['secc'], prefix='sect')\n",
    "df = pd.concat([df, sect_dummies], axis=1)\n",
    "print(\"Age and sector dummies created.\")\n",
    "\n",
    "# Label sector variables (as comments since Python doesn't have variable labels like Stata)\n",
    "# sect1: \"industrias extractivas\"\n",
    "# sect2: \"alimentación y bebidas\"\n",
    "# sect3: \"madera y papel\"\n",
    "# sect4: \"artes graficas\"\n",
    "# sect5: \"química, farmacia y refino\"\n",
    "# sect6: \"otros prod. minerales no met.\"\n",
    "# sect7: \"metalurgia\"\n",
    "# sect8: \"prod. informáticos, electrónicos y ópticos\"\n",
    "# sect9: \"fab. mat. de transporte y muebles\"\n",
    "# sect10: \"e. eléctrica, gas, vapor\"\n",
    "# sect11: \"suministro de agua\"\n",
    "# sect12: \"construcción\"\n",
    "# sect13: \"comercio al por mayor\"\n",
    "# sect14: \"comercio al por menor\"\n",
    "# sect15: \"transporte\"\n",
    "# sect16: \"almacenamiento\"\n",
    "# sect17: \"hostelería\"\n",
    "# sect18: \"información y comunicaciones\"\n",
    "# sect19: \"act. financieras y de seguros\"\n",
    "# sect20: \"act. inmobiliarias\"\n",
    "# sect21: \"act. profesionales, científicas y técnicas\"\n",
    "# sect22: \"act. administrativas y servicios auxliares\"\n",
    "# sect23: \"aapp y defensa\"\n",
    "# sect24: \"educación\"\n",
    "# sect25: \"act. sanitarias y de servicios sociales\"\n",
    "# sect26: \"act. artísticas y recreativas\"\n",
    "# sect27: \"otros servicios\"\n",
    "\n",
    "# ICT variable\n",
    "df['ict'] = 0\n",
    "# Check if columns exist before using them\n",
    "sect_cols = [col for col in df.columns if col.startswith('sect')]\n",
    "if 'sect_8' in df.columns:\n",
    "    df.loc[(df['sect_8'] == 1) | (df['sect_18'] == 1) | (df['sect_19'] == 1) | \n",
    "           (df['sect_21'] == 1) | (df['sect_26'] == 1), 'ict'] = 1\n",
    "\n",
    "# High Value added\n",
    "df['v_added'] = 0\n",
    "if 'sect_18' in df.columns:\n",
    "    df.loc[(df['sect_18'] == 1) | (df['sect_5'] == 1) | (df['sect_9'] == 1) | \n",
    "           (df['sect_19'] == 1) | (df['sect_8'] == 1), 'v_added'] = 1\n",
    "\n",
    "# Create market dummy variables\n",
    "market_dummies = pd.get_dummies(df['mercado'], prefix='market')\n",
    "df = pd.concat([df, market_dummies], axis=1)\n",
    "\n",
    "# Create convenio dummy variables\n",
    "conv_dummies = pd.get_dummies(df['convenio'], prefix='conv_')\n",
    "df = pd.concat([df, conv_dummies], axis=1)\n",
    "\n",
    "# Create estudios dummy variables\n",
    "estudios_dummies = pd.get_dummies(df['cestudio'], prefix='estudios')\n",
    "df = pd.concat([df, estudios_dummies], axis=1)\n",
    "\n",
    "# Generate anoanti2\n",
    "df['anoanti2'] = df['anoanti'] ** 2\n",
    "\n",
    "# Generate contrato variable\n",
    "df['contrato'] = 0\n",
    "df.loc[(df['indefin'] == 1) & (df['parcial'] == 0), 'contrato'] = 1\n",
    "df.loc[(df['indefin'] == 1) & (df['parcial'] == 1), 'contrato'] = 2\n",
    "df.loc[(df['indefin'] == 0) & (df['parcial'] == 0), 'contrato'] = 3\n",
    "df.loc[(df['indefin'] == 0) & (df['parcial'] == 1), 'contrato'] = 4\n",
    "\n",
    "print(\"Data processing completed successfully!\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Years in dataset: {sorted(df['year'].unique())}\")\n",
    "\n",
    "# Clean up the extracted folder\n",
    "print(f\"Cleaning up extracted folder: {data_base_path}\")\n",
    "if os.path.exists(data_base_path):\n",
    "    shutil.rmtree(data_base_path)\n",
    "    print(\"Cleanup successful.\")\n",
    "else:\n",
    "    print(\"Folder not found, skipping cleanup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b805aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data types for Parquet compatibility...\n",
      "Converting 14 columns to string type: ['ordenccc', 'ordentra', 'region', 'secc', 'estrato2', 'cno2', 'responsa', 'cestudio', 'siespm1', 'siespm2', 'siespa1', 'siespa2', 'siespa3', 'siespa4']\n",
      "Saving processed data to ..\\data\\EES_procesado.parquet...\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to a Parquet file\n",
    "\n",
    "# FIX: Convert all 'object' and 'category' dtype columns to 'string' for Parquet compatibility.\n",
    "# This prevents errors with pyarrow when saving the file.\n",
    "print(\"Fixing data types for Parquet compatibility...\")\n",
    "cols_to_convert = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "if len(cols_to_convert) > 0:\n",
    "    print(f\"Converting {len(cols_to_convert)} columns to string type: {list(cols_to_convert)}\")\n",
    "    for col in cols_to_convert:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "# Save the file\n",
    "output_path = os.path.join('..', 'data', 'EES_procesado.parquet')\n",
    "print(f\"Saving processed data to {output_path}...\")\n",
    "df.to_parquet(output_path)\n",
    "print(\"Data saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftimeseriesII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
